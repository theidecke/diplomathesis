	\chapter{Monte--Carlo--Markov--Chain--Verfahren}\label{chapter:mcmc}
	Im vorigen Abschnitt haben wir gesehen, wie mit unabh"angig gezogenen identisch verteilten Samples der Erwartungswert einer Zufallsgr"o"se abgesch"atzt werden kann. In diesem Fall der numerische Wert eines Integrals. Insbesondere werden wir in Abschnitt \ref{sec:mc_radiativetransfer} sehen, wie wir damit den Wert einer Messung (im Sinne von Abschnitt \ref{sec:measurement_equation}) des Strahlungsintensit"atsfeldes sch"atzen k"onnen. Beispielsweise kann dies ein Pixel eines (virtuellen) CCD--Sensors sein. Um ein Bild des kompletten CCD--Sensors zu erhalten w"urden wir daher jeden Pixelwert als eigenes Me"sproblem auffassen und unabh"angig voneinander l"osen.
	
	Eine zweite M"oglichkeit ist aber, die vielen kleinen Pixelsensoren zu einem gro"sen Sensor zusammenzufassen, der die ganze CCD--Fl"ache abdeckt, und die gezogenen Werte nicht sofort zu einem Durchschnittswert "uber den ganzen Sensor zu mitteln, sondern vorher entsprechend der (bis dahin nicht vorhandenen) Pixelzugeh"origkeit zu Klassen zusammenzufassen und in jeder Klasse (und damit in jedem Pixel) getrennt zu mitteln. Dies hat den Vorteil, dass wir durch den gr"o"seren Sensor schon vorher an allen Pixeln ``Interesse bekunden'' und damit mehr M"oglichkeiten (in Form von Lichtpfaden) haben, ein beitragendes Sample zu erhalten. Berechnen wir hingegen alle Pixelsensor--Messwerte unabh"angig voneinander, ist die Chance gro"s, bei der Messung eines Pixels genau die Pfade abzulehnen, die zum n"achsten Pixel einen Beitrag geleistet h"atten.
	
	Hieran zeigt sich, dass wir h"aufig nicht an einzelnen, f"ur sich alleine stehenden Messwerten interessiert sind, sondern an der Verteilung der Samples "uber verschiedene Klassen, z.B. die Verteilung der Photonen auf einem CCD--Sensor oder die Verteilung von Photonen "uber die verschiedenen Wellenl"angen in einem Spektrum. In all diesen F"allen lohnt es sich, die Messung mit dem gr"o"stm"oglichen Sensor vorzunehmen und die Klasseneinteilung und Mittelung danach vorzunehmen.

	In vielen F"allen in denen solch eine nachgezogene Klasseneinteilung sinnvoll ist, ist die relative Verteilung der Samples "uber die Klassen wichtiger als die absoluten Messwerte f"ur die einzelnen Klassen. Bei manchen Problemen, beispielsweise bei der Sch"atzung eines Spektrums, sind wir sogar nur an diesen relativen H"aufigkeiten der Samples interessiert und die absoluten Messwerte sind nicht relevant. In solch einem Fall ist die Normierung der Wahrscheinlichkeitsverteilung, aus der die Samples gezogen werden nicht n"otig. Hier reicht es aus, "uber ein Verfahren zu verf"ugen, das Samples aus der Verteilung ziehen kann, ohne ihre Wahrscheinlichkeiten mitzuliefern.
	
	Genau dies leisten sogenannte {\em Mon\-te--Car\-lo--Mar\-kov--Chain--Ver\-fahr\-en} (MCMC--Verfahren). Sie stellen Verfahren dar, um aus einem Zustandsraum $\Omega$ gem"a"s einer gegebenen Wahrscheinlichkeitsdichte $f$ verteilte Werte zu ziehen. Dies wird durch die Konstruktion eines Zufallspfads ({\em random~walk}) im Zustandsraum, dirigiert durch eine Markov--Kette, erreicht. Dabei mu"s sichergestellt werden, dass die so erzeugten Werte auch gem"a"s $f$ verteilt sind und insbesondere jeder Punkt im Zustandsraum, auf dem $f$ nicht verschwindet, auch erreicht werden kann.
	
	Wie im n"achsten Abschnitt gezeigt wird, ist dies mit erstaunlich wenig Aufwand m"oglich. Selbst wenn doch eine Normierung n"otig ist, kann es sinnvoll sein, die Normierung mit einem klassischen Monte--Carlo--Integrations--Verfahren "uber den Gesamtsensor zu bestimmen und die Verteilung des Samples "uber die Klassen innerhalb des Sensors mit einem MCMC--Verfahren zu ermitteln.
	
	Die Kombination aus Vielseitigkeit, M"achtigkeit und Einfachheit hat MCMC--Verfahren in vielen Bereichen\footnote{Beispiele finden sich u.a. in der statistischen Physik, in der Finanzmathematik und zur Berechnung von A--posteriori--Wahrscheinlichkeiten in der Bayes'schen Statistik \citep{Geweke:1989p10465}, z.B. mit Anwendungen in der Bioinformatik und Medizin. Weitere interessante und ungew"ohnliche Anwendungen finden sich in \citep{Diaconis:2009p4122}} zu einem Hauptverfahrensbestandteil gemacht.
	
	
	\section{Metropolis--Hastings--Algorithmus}
	Unter den MCMC--Verfahren ist eines der bekanntesten der {\em Metropolis--Hastings--Algorithmus} (MH), der durch eine Arbeit in der statistischen Physik von \citet{Metropolis:1953p3364} in einer einfachen Form vorgestellt und sp"ater durch \citet{Hastings:1970p3387} verallgemeinert wurde.

	Beim MH--Algorithmus ziehen wir aus einem Zustandsraum $\Omega$ Elemente $x \in \Omega$ gem"a"s der (nicht notwendigerweise normierten!) Wahrscheinlichkeitsdichte $f : \Omega \rightarrow \mathbb{R}_{\geq 0}$. Die Elemente werden dabei mit einem Zufallspfad durch den Zustandsraum generiert. Wir ver"andern dazu den aktuellen Zustand $x$ nach einem frei w"ahlbaren Schema (im Folgenden Mutation genannt) in einen neuen Zustand $x'$.
	Dabei stellen wir folgende Bedingungen an eine Mutation:
	\begin{itemize}
		\item{wenn der "Ubergang von Zustand $x$ nach $x'$ m"oglich ist, muss auch der "Ubergang zur"uck von $x'$ nach $x$ m"oglich sein}
		\item{es muss jeder Zustand $x \in \Omega$ durch eine Kette von "Uberg"angen erreichbar sein (Ergodizit"at)}
		\item{Die "Ubergangswahrscheinlichkeit $T(x'|x)$ durch unser Mutations--Schema von Zustand $x$ zum Zustand $x'$ zu kommen muss f"ur gegebenes $x$ und $x'$ berechenbar sein}
	\end{itemize}
	Mutationen sind also, etwas formaler formuliert, bedingte Wahrscheinlichkeitsverteilungen, die durch das Herkunftselement parametrisiert sind, nicht normiert sein m"ussen und f"ur die
	$$\forall x,x'\in\Omega : \quad T(x'|x)>0 \Leftrightarrow T(x|x')>0$$
	wahr ist. Hierin k"onnen wir eine Parallele zum {\em Importance Sampling} aus Abschnitt \ref{subsec:importancesampling} entdecken, bei dem wir auch die A--priori--Wahr\-schein\-lich\-keits\-ver\-tei\-lung, aus der die Werte gezogen werden, selber w"ahlen k"onnen ohne das Ergebnis der Integration zu verf"alschen. W"ahrend wir uns beim Importance Sampling allerdings f"ur eine einzige Verteilung zur Generierung der gesamten Stichprobe entscheiden m"ussen, haben wir beim {\em MH--Algorithmus} die M"oglichkeit, f"ur jeden aktuellen Zustand eine eigene Verteilung festzulegen, aus der ein Vorschlag f"ur den neuen Zustand gezogen wird.
	Das bedeutet, Mutationen k"onnen (und sollten) f"ur effizientes und verl"assliches Verhalten an das spezifische Samplingproblem angepasst werden, indem die Eigenschaften der interessierenden Wahrscheinlichkeitsdichte $f$ und des Zustandsraumes $\Omega$ miteinbezogen werden. Sind beispielsweise exakte oder n"aherungsweise g"ultige Invarianten von $f$ bez"uglich seiner Zustandsraumkoordinaten bekannt, k"onnen diese genutzt werden, um Samples "ahnlicher Wahrscheinlichkeitsdichte aber gering korrelierter Zustandsraumkoordinaten zu ziehen.
	
		
	\paragraph{Detailed Balance:}
	Da die Mutation, mit der wir den neuen Zustand generieren, nichts mit der Wahrscheinlichkeitsdichte $f$ zu tun haben muss, brauchen wir eine M"oglichkeit die Verteilung der Zust"ande gem"a"s $f$ trotzdem sicherzustellen.
	
	Betrachten wir eine gro"se Zahl von gleichartigen aber unabh"angigen Markov--Ketten, die alle mit einer gewissen Wahrscheinlichkeit $p(x'|x)$ vom Zustand $x$ in den Zustand $x'$ "ubergehen und mitteln "uber die aktuellen Zust"ande aller Markov--Ketten. Dann ist eine M"oglichkeit eine station"are Zustandsdichte $f$ zu erreichen, zu verlangen, dass
	\begin{equation}
		\forall x,x' \in \Omega :\quad f(x)p(x'|x) = f(x')p(x|x')
		\label{eq:dynamic_equlibrium}
	\end{equation}
	({\em =Detailed Balance}) gilt, d.h. dass sich die "Ubergangsraten zwischen zwei beliebigen Zust"anden im dynamischen Gleichgewicht befinden.
	Da $T$ die "Ubergangswahrscheinlichkeiten aber schon festlegt, behalten wir uns das Recht vor, einen durch Ziehen aus $T$ vorgeschlagenen Zustands"ubergang nur mit der Wahrscheinlichkeit $a(x'|x)$ anzunehmen und ansonsten abzulehnen,	um {\em Detailed Balance} sicherstellen zu k"onnen:
	\begin{equation}
		p(x'|x) = T(x'|x)a(x'|x)
		\label{eq:acceptance_prob_intro}
	\end{equation}
	\begin{equation}
		(\ref{eq:dynamic_equlibrium}) \stackrel{(\ref{eq:acceptance_prob_intro})}{\Longrightarrow}
		\forall x,x' \in \Omega :\quad f(x)T(x'|x)a(x'|x) = f(x')T(x|x')a(x|x')
		\label{eq:detailedbalance}
	\end{equation}
	Dies l"asst noch immer verschiedene M"oglichkeiten zu, die Akzeptanzwahrscheinlichkeit zu bestimmen. Eine effiziente und dadurch beliebte Wahl ist dabei Folgende: ist $f(x')>f(x)$ nehmen wir den neuen Zustand auf jeden Fall an, ansonsten mit der Wahrscheinlichkeit $(f(x')T(x|x'))/(f(x)T(x'|x))$. Dies l"asst sich zusammenfassen zu
	\begin{equation}
		a(x'|x)=\text{min}\left(1,\frac{f(x')T(x|x')}{f(x)T(x'|x)}\right)
		\label{eq:acceptanceratio}
	\end{equation}
	Diese Wahl der Akzeptanzwahrscheinlichkeit erf"ullt die Detailed--Balance--Bedingung (\ref{eq:detailedbalance}).
	
	
	
	\paragraph{Pseudocode:}
	In Pseudocode sieht der Algorithmus dann wie folgt aus:
	\begin{algorithmic}
		\STATE $x_1 \leftarrow$ Anfangszustand
		\FOR{$i=1$ to $N$}
			\STATE $x'\leftarrow$ ziehe Wert gem"a"s $T(x'|x_i)$
			\STATE $a(x'|x_i) \leftarrow \text{min}\left(1, \frac{f(x')T(x|x')}{f(x)T(x'|x)}\right)$
			\STATE $u\leftarrow$ Zufallszahl aus $[0,1]$
			\IF{$u < a(x'|x_i)$}	\STATE $x_{i+1} \leftarrow x'$
			\ELSE	\STATE $x_{i+1} \leftarrow x_i$
			\ENDIF
	  \ENDFOR
	\end{algorithmic}
	Als Ergebnis erhalten wir eine Liste von Werten, die gem"a"s $f$ verteilt sind.
	Die Tatsache, dass die Normierung von $f$ f"ur die Funktion des Verfahrens nicht notwendig ist, kann einerseits von Vorteil sein, und bei bestimmten Problemen die effiziente Generierung einer Stichprobe erst m"oglich machen. Sie bedeutet allerdings, dass wir uns bei Bedarf eine Normierung auf andere Weise beschaffen m"ussen, da die gezogenen Werte ebenfalls nicht normiert sind. Die Werte sind au"serdem nicht unabh"angig, sondern im Gegenteil h"aufig stark korreliert.

	\paragraph{Konvergenz:}Bei klassischer Monte--Carlo--Integration hatten wir in Abschnitt \ref{subsec:integrationsproblem_comparison} gezeigt, dass bei einer Standard--Abweichung eines Wertes von $$\sigma^*:=\sigma\left[\frac{f(X_i)}{p(X_i)}\right]$$ die Standard--Abweichung des Mittelwertes von N unabh"angig gezogenen Werten $\sigma^*/\sqrt{N}$ betr"agt. Sind die Werte hingegen korreliert, gilt f"ur die Standard--Abweichung des Mittelwertes die Absch"atzung \citep[siehe][VII.\;\S3(8)]{Renyi:1964p10655}
	$$\sigma\leq \sigma^*\sqrt{\frac{1+2\sum_{i=1}^N R(i)}{N}},$$
	wobei $R(|j-i|)\leq 1$ eine obere Schranke f"ur die Korrelation zwischen $f(X_i)/p(X_i)$ und $f(X_j)/p(X_j)$ ist.
	Eine gro"se Korrelation kann sich also negativ auf die Konvergenzrate des Mittelwertes (und anderer statistischer Kenngr"o"sen) auswirken. Daher gilt es bei der Konstruktion einer Mutation zwei Aspekte gegeneinander abzuw"agen: einerseits ist es w"unschenswert in einem Mutationsschritt m"oglichst ``gro"se Schritte'' zu machen um die Korrelation der Werte kleinzuhalten, andererseits ist es in selten gezogenen Bereichen mit hohem Beitrag w"unschenswert kleine Schritte zu machen, um diesen Bereich gut abzudecken. W"ahrend ersteres Verfahren meist mit einer kleinen Akzeptanzwahrscheinlichkeit einhergeht, f"uhren kleine Mutationen tendenziell zu hohen Akzeptanzwahrscheinlichkeiten. Beide ziehen aber in zu extremer Form hohe Korrelation der Samples nach sich, bei zu gro"sen Schritten aufgrund der geringen Akzeptanzwahrscheinlichkeit und daher mehrfacher Gewichtung desselben Samples, bei zu kleinen Schritten aufgrund der gro"sen "Ahnlichkeit der vorgeschlagenen Samples. Daher sind sowohl zu hohe als auch zu kleine Akzeptanzwahrscheinlichkeiten meistens ein Zeichen suboptimalen Samplings. In \citep{Roberts:1997p5198} wird zur Steuerung der Mutationsst"arke f"ur die Akzeptanzwahrscheinlichkeit ein anzustrebender Wert von $\approx 0.23$ bei hochdimensionalen Problemen empfohlen.

	
	
	\section{Robuster Metropolis--Hastings--Algorithmus}
	Wir haben in Abschnitt \ref{subsec:importancesampling} festgestellt, dass die Effizienz des einfachen Monte--Carlo--Sch"atzers erheblich verbessert werden kann, wenn f"ur {\em Importance Sampling} eine geeignete A--priori--Wahrscheinlichkeitsdichte $p$ bekannt und samplebar ist. Parallel dazu haben wir im vorigen Abschnitt gesehen, dass es auch f"ur ein effizientes Funktionieren des {\em Metropolis--Hastings--Algorithmus} wichtig ist, die Mutationen an das Problem anzupassen. Meistens geschieht dies dadurch, dass verschiedene Mutationen erdacht werden, die jeweils in einem Teilbereich des Zustandsraumes effizient sind. Als Beispiel k"onnten wir bei jedem neuen Sample zuf"allig zwischen einer Mutation, die gro"se Schritte macht und einer anderen, die nur kleine Ver"anderungen vornimmt, w"ahlen. Zur Generierung eines neuen Samples wird dann zuf"allig eine der Mutationen ausgew"ahlt und auf das letzte Sample angewandt.
	
	In \citep{Kelemen:2002p8514} wird hingegen eine elegante Variante des Metropolis--Algorithmus vorgeschlagen, die im Wesentlichen mit nur einer Mutation auskommt und trotzdem "uber die gew"unschte Eigenschaft verf"ugt sich an die lokalen Gegebenheiten anpassen zu k"onnen. Dem Verfahren liegt dabei folgende Idee zugrunde: Wenn es m"oglich w"are den Zustandsraum $\Omega$ und die Wahrscheinlichkeitsdichte $f$ so zu transformieren, 	dass $f$ gleichm"a"siger verteilt ist, dann w"urde es ausreichen eine einzige Mutation auf diesem transformierten Zustandsraum operieren zu lassen. Dann w"urden Teilgebiete von $\Omega$ mit hohen Spitzenwerten in $f$ zu gr"o"seren Gebieten ``gedehnt'', und gr"o"sere Teilgebiete mit kleinen $f$--Werten ``gestaucht'' werden, und $f$ dadurch gleichm"a"siger werden lassen. Eine Mutation, die auf dem transformierten Zustandsraum operiert, w"urde dann automatisch dort kleinere Schritte machen, wo $f$ pl"otzlich gro"s wird und gr"o"sere Schritte dort, wo $f$ flach und klein ist.
	
	Solch eine Transformation bekommen wir ``geschenkt'', falls wir Punkte im Zustandsraum mittels {\em Importance Sampling} generieren, was bei komplizierteren Problemen (wie dem Strahlungstransportproblem) ohnehin meist der Fall ist (siehe Abschnitt \ref{sec:mc_radiativetransfer}). Schauen wir uns dazu als Beispiel das Integrationsproblem
	\begin{equation}
		I=\int_\Omega f(x) d\mu(x)\approx \frac{1}{N}\sum_{i=0}^{N-1} \frac{f(X_i)}{p(X_i)}
		\label{eq:transformedintegral1}
	\end{equation}
	aus Abschnitt \ref{subsec:integrationsproblem} an. Die Samples aus $p$ werden zumeist durch Transformation gleichf"ormig verteilter Zufallszahlen aus dem Einheitsinterval $[0,1]$ generiert. Daher k"onnen wir eine gezogene Konfiguration von (potentiell unendlich vielen) Zufallszahlen als Koordinaten im unendlichdimensionalen Einheitsw"urfel $[0,1]^\infty$ auffassen. Nennen wir diesen den {\em prim"aren Sample--Raum} $\mathcal{U}$ und bezeichnen die Transformation vom prim"aren Sample--Raum in unseren Zustandsraum als
	$$S : \mathcal{U} \to \Omega\,,\quad x=S(u).$$
	Dann k"onnen wir unser Integral (\ref{eq:transformedintegral1}) auch als transformiertes Integral
	$$I=\int_\mathcal{U} f(S(u)) \left|\frac{dS(u)}{du}\right|du=\int_\mathcal{U} \frac{f(S(u))}{p_S(u)}du$$
	schreiben, wobei
	$$\left|\frac{dS(u)}{du}\right|=\frac{1}{p_S(u)}$$
	die Jacobi--Determinante der Abbildung $S$ ist. Bildlich gesprochen dr"uckt die Jacobi--Determinante die lokale Dehnung bzw. Stauchung einer Transformation zwischen zwei R"aumen aus. Wenn $u$ also eine gleichm"a"sig verteilte Zufallsvariable darstellt, ist $p_S(u)$ die Wahrscheinlichkeitsdichte von $x=S(u)$. Da $S$ die Zufallszahlen aus dem prim"aren Sample--Raum vermehrt auf Punkte im Zustandsraum $\Omega$ mit hohem $f$ abbildet, variiert unser neuer Integrand $f(S(u))/p_S(u)$ nicht mehr so stark, ist also flacher geworden. Unsere Mutation, die nun im prim"aren Sample--Raum mit konstanter durchschnittlicher Schrittweite agiert, passt sich dadurch automatisch an die lokalen Gegebenheiten an, d.h. sie macht kleine Schritte in $\Omega$ wenn $f$ gro"s ist, und gr"o"sere Schritte, wenn $f$ klein ist. Die Effizienz des Verfahrens k"onnen wir nun also dadurch verbessern, dass wir das Importance Sampling besser auf das Problem abstimmen. Die Tatsache, dass nun die Mutationen indirekt durch die Transformation vom prim"aren Sampleraum in den Zustandsraum definiert werden, erh"oht auch die Modularit"at und damit die Wiederverwendbarkeit des Algorithmus in Form eines Computerprogramms (siehe dazu Abschnitt \ref{cha:program_description} f"ur Details).

	Zum Vorschlagen neuer Samples benutzen wir zwei Mutationen. Zum einen k"onnen durch W"ahlen eines neuen Satzes gleichf"ormig verteilter Zufallszahlen aus $\mathcal{U}$ {\em frische} Samples vorgeschlagen werden. Dies stellt sicher, dass jeder Punkt in $\mathcal{U}$ bzw. $\Omega$ erreicht werden kann und stellt so die Ergodizit"at des Verfahrens sicher und macht es robuster. Bei sehr schwierigen Sampling--Problemen verh"alt sich das Verfahren dann schlimmstenfalls wie ein klassischer Monte--Carlo--Sampler mit Importance Sampling, bei dem jedes Sample unabh"angig gezogen wird.
	Die andere Mutation addiert zu den vorhandenen Koordinaten des aktuellen Samples aus $\mathcal{U}$ jeweils eine kleine St"orung, so dass jede Koordinate sich "andert aber mit gro"ser Wahrscheinlichkeit in der N"ahe der alten Koordinate landet. Die St"orung ist dabei symmetrisch um Null, d.h. es ist gleichwahrscheinlich einen Versatz $\Delta u$ zu ziehen wie $-\Delta u$. Die Koordinaten werden dabei als periodisch angesehen, d.h. bei "Uberschreiten des rechten Randes von $[0,1]$ wird der ganzzahlige Teil abgeschnitten um wieder im Einheitsintervall zu landen. Dies birgt einen Effizienz--Vorteil, da die Symmetrie der St"orung bedeutet, dass f"ur die "Ubergangswahrscheinlichkeiten
	\begin{equation}
	  T(u'|u)=T(u|u')
	  \label{eq:symmetric_transitionprob}
	\end{equation}
	gilt und sie sich daher in der Berechnung der Akzeptanzwahrscheinlichkeit
	$$a(u'|u)=\text{min}\left(1,\frac{f(S(u'))T(u|u')}{f(S(u))T(u'|u)}\right)\stackrel{(\ref{eq:symmetric_transitionprob})}{=}\text{min}\left(1,\frac{f(S(u'))}{f(S(u))}\right)$$
	herausk"urzt. Im Falle der {\em frischen Mutation} k"urzt sich die "Ubergangswahrscheinlichkeit $T$ ebenfalls heraus, da $\mathcal{U}$ gleichm"a"sig gesampled wird.
	In Pseudocode sieht der Algorithmus dann wie folgt aus:
	\begin{algorithmic}
		\STATE $u \leftarrow$ Anfangszustand
		\STATE $x_1 \leftarrow S(u)$
		\FOR{$i=1$ to $N$}
			\STATE $r\leftarrow$ Zufallszahl aus $[0,1]$
			\IF[Mutation schl"agt frisches Sample vor]{$r < p_\text{fresh}$}
						\STATE $T \leftarrow T_\text{fresh}$
			\ELSE[Mutation schl"agt leicht abgewandeltes Sample vor]	\STATE $T \leftarrow T_\text{perturb}$
			\ENDIF
			\STATE $u'\leftarrow$ ziehe Wert gem"a"s $T(u'|u)$
			\STATE $x' \leftarrow S(u')$
			\STATE $a(u'|u) \leftarrow \text{min}\left(1,\frac{f(x')}{f(x_i)}\right)$
			\STATE $r\leftarrow$ Zufallszahl aus $[0,1]$
			\IF{$r < a(u'|u)$}
			  \STATE $x_{i+1} \leftarrow x'$
			  \STATE $u \leftarrow u'$
			\ELSE	\STATE $x_{i+1} \leftarrow x_i$
			\ENDIF
	  \ENDFOR
	\end{algorithmic}

