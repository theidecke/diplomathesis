	\chapter{Monte--Carlo--Markov--Chain--Verfahren}\label{chapter:mcmc}
	Im vorigen Abschnitt haben wir gesehen, wie mit unabhängig gezogenen identisch verteilten Samples der Erwartungswert einer Zufallsgröße abgeschätzt werden kann. Im in dieser Arbeit behandelten Fall der numerische Wert eines Integrals. Insbesondere werden wir in Abschnitt \ref{sec:mc_radiativetransfer} sehen, wie wir damit den Wert einer Messung (im Sinne von Abschnitt \ref{sec:measurement_equation}) des Strahlungsfeldes schätzen können. Beispielsweise kann dies ein Pixel eines (virtuellen) CCD--Sensors sein. Um ein Bild des kompletten CCD--Sensors zu erhalten würden wir daher jeden Pixelwert als eigenes Messproblem auffassen und unabhängig von den anderen lösen.
	
	Eine zweite Möglichkeit ist aber, die vielen kleinen Pixelsensoren zu einem großen Sensor zusammenzufassen, der die ganze CCD--Fläche abdeckt, und die gezogenen Werte nicht sofort zu einem Durchschnittswert über den ganzen Sensor zu mitteln, sondern vorher entsprechend der (bis dahin nicht vorhandenen) Pixelzugehörigkeit zu Klassen zusammenzufassen und in jeder Klasse (und damit in jedem Pixel) getrennt zu mitteln. Dies hat den Vorteil, dass wir durch den größeren Sensor schon vorher an allen Pixeln ``Interesse bekunden'' und damit mehr Möglichkeiten (in Form von Lichtpfaden) haben, ein beitragendes Sample zu erhalten. Berechnen wir hingegen alle Pixelsensor--Messwerte unabhängig voneinander, ist die Chance groß, bei der Messung eines Pixels genau die Pfade abzulehnen, die zum nächsten Pixel einen Beitrag geleistet hätten.
	
	Hieran zeigt sich, dass wir häufig nicht an einzelnen, für sich alleine stehenden Messwerten interessiert sind, sondern an der Verteilung der Samples über verschiedene Klassen, z.B. die Verteilung der Photonen auf einem CCD--Sensor oder die Verteilung von Photonen über die verschiedenen Wellenlängen in einem Spektrum. In all diesen Fällen lohnt es sich, die Messung mit dem größtmöglichen Sensor vorzunehmen und die Klasseneinteilung und Mittelung danach vorzunehmen.

	In vielen Fällen, in denen solch eine nachgezogene Klasseneinteilung sinnvoll ist, ist die relative Verteilung der Samples über die Klassen wichtiger als die absoluten Messwerte für die einzelnen Klassen. Bei manchen Problemen, beispielsweise bei der Schätzung eines Spektrums, sind wir sogar nur an diesen relativen Häufigkeiten der Samples interessiert und die absoluten Messwerte sind nicht relevant. In solch einem Fall ist die Normierung der Wahrscheinlichkeitsverteilung, aus der die Samples gezogen werden, nicht nötig. Hier genügt ein Verfahren, das Samples aus der Verteilung ziehen kann, ohne ihre Wahrscheinlichkeiten mitzuliefern.
	
	Genau dies leisten sogenannte {\em Mon\-te--Car\-lo--Mar\-kov--Chain--Ver\-fahr\-en} (MCMC--Verfahren). Sie stellen Verfahren dar, um aus einem Zustandsraum $\Omega$ gemäß einer gegebenen Wahrscheinlichkeitsdichte $f$ verteilte Werte zu ziehen. Dies wird durch die Konstruktion eines Zufallspfads ({\em random~walk}) im Zustandsraum, dirigiert durch eine Markov--Kette, erreicht. Dabei muß sichergestellt werden, dass die so erzeugten Werte auch gemäß $f$ verteilt sind und insbesondere jeder Punkt im Zustandsraum, auf dem $f$ nicht verschwindet, auch erreicht werden kann.
	
	Wie im nächsten Abschnitt gezeigt wird, ist dies mit wenig Aufwand möglich. Selbst wenn doch eine Normierung nötig ist, kann es sinnvoll sein, die Verteilung des Samples über die Klassen innerhalb des Sensors mit einem MCMC--Verfahren zu ermitteln und die Normierung unabhängig mit einem klassischen Monte--Carlo--Integrations--Verfahren über den Gesamtsensor zu bestimmen.
	
	Die Kombination aus Vielseitigkeit, Mächtigkeit und Einfachheit hat MCMC--Verfahren in vielen Bereichen\footnote{Beispiele finden sich u.a. in der statistischen Physik, in der Finanzmathematik und zur Berechnung von A--posteriori--Wahrscheinlichkeiten in der Bayes'schen Statistik \citep{Geweke:1989p10465}, z.B. mit Anwendungen in der Bioinformatik und Medizin. Weitere teilweise ungewöhnliche Anwendungen finden sich in \citep{Diaconis:2009p4122}} zu einem Hauptverfahrensbestandteil gemacht.
	
	
	\section{Metropolis--Hastings--Algorithmus}
	Unter den MCMC--Verfahren ist eines der bekanntesten der {\em Metropolis--Hastings--Algorithmus} (MH), der durch eine Arbeit in der statistischen Physik von \citet{Metropolis:1953p3364} in einer einfachen Form vorgestellt und später durch \citet{Hastings:1970p3387} verallgemeinert wurde.

	Beim MH--Algorithmus ziehen wir aus einem Zustandsraum $\Omega$ Elemente $x \in \Omega$ gemäß der (nicht notwendigerweise normierten!) Wahrscheinlichkeitsdichte $f : \Omega \rightarrow \mathbb{R}_{\geq 0}$. Die Elemente werden dabei mit einem Zufallspfad durch den Zustandsraum generiert. Wir verändern dazu den aktuellen Zustand $x$ nach einem frei wählbaren Schema (im Folgenden Mutation genannt) in einen neuen Zustand $x'$.
	Dabei stellen wir folgende Bedingungen an eine Mutation:
	\begin{itemize}
		\item{wenn der Übergang von Zustand $x$ nach $x'$ möglich ist, muss auch der Übergang zurück von $x'$ nach $x$ möglich sein}
		\item{es muss jeder Zustand $x \in \Omega$ durch eine Kette von Übergängen erreichbar sein (Ergodizität)}
		\item{Die Übergangswahrscheinlichkeit $T(x'|x)$ durch unser Mutations--Schema von Zustand $x$ zum Zustand $x'$ zu kommen, muss für ein gegebenes $x$ und $x'$ berechenbar sein}
	\end{itemize}
	Mutationen sind also, etwas formaler formuliert, bedingte Wahrscheinlichkeitsverteilungen, die durch das Herkunftselement parametrisiert sind, nicht normiert sein müssen und für die
	$$\forall x,x'\in\Omega : \quad T(x'|x)>0 \Leftrightarrow T(x|x')>0$$
	wahr ist. Hierin können wir eine Parallele zum {\em Importance Sampling} aus Abschnitt \ref{subsec:importancesampling} entdecken, bei dem wir auch die A--priori--Wahr\-schein\-lich\-keits\-ver\-tei\-lung, aus der die Werte gezogen werden, selber wählen können, ohne das Ergebnis der Integration zu verfälschen. Während wir uns beim Importance Sampling allerdings für eine einzige Verteilung zur Generierung der gesamten Stichprobe entscheiden müssen, haben wir beim {\em MH--Algorithmus} die Möglichkeit, für jeden aktuellen Zustand eine eigene Verteilung festzulegen, aus der ein Vorschlag für den neuen Zustand gezogen wird.
	Das bedeutet, Mutationen können (und sollten) für effizientes und verlässliches Verhalten an das spezifische Samplingproblem angepasst werden, indem die Eigenschaften der relevanten Wahrscheinlichkeitsdichte $f$ und des Zustandsraumes $\Omega$ miteinbezogen werden. Sind beispielsweise exakte oder näherungsweise gültige Invarianten von $f$ bezüglich seiner Zustandsraumkoordinaten bekannt, können diese genutzt werden, um Samples ähnlicher Wahrscheinlichkeitsdichte aber gering korrelierter Zustandsraumkoordinaten zu ziehen.
	
		
	\paragraph{Detailed Balance:}
	Da die Mutation, mit der wir den neuen Zustand generieren, nichts mit der Wahrscheinlichkeitsdichte $f$ zu tun haben muss, brauchen wir eine Möglichkeit, die Verteilung der Zustände gemäß $f$ trotzdem sicherzustellen.
	
	Betrachten wir eine große Zahl von gleichartigen aber unabhängigen Markov--Ketten, die alle mit einer gewissen Wahrscheinlichkeit $p(x'|x)$ vom Zustand $x$ in den Zustand $x'$ übergehen und mitteln über die aktuellen Zustände aller Markov--Ketten. Dann ist eine Möglichkeit eine stationäre Zustandsdichte $f$ zu erreichen, zu verlangen, dass
	\begin{equation}
		\forall x,x' \in \Omega :\quad f(x)p(x'|x) = f(x')p(x|x')
		\label{eq:dynamic_equlibrium}
	\end{equation}
	({\em =Detailed Balance}) gilt, d.h. dass sich die Übergangsraten zwischen zwei beliebigen Zuständen im dynamischen Gleichgewicht befinden.
	Da $T$ die Übergangswahrscheinlichkeiten aber schon festlegt, behalten wir uns das Recht vor, einen durch Ziehen aus $T$ vorgeschlagenen Zustandsübergang nur mit der Wahrscheinlichkeit $a(x'|x)$ anzunehmen und ansonsten abzulehnen,	um {\em Detailed Balance} sicherstellen zu können:
	\begin{equation}
		p(x'|x) = T(x'|x)a(x'|x)
		\label{eq:acceptance_prob_intro}
	\end{equation}
	\begin{equation}
		(\ref{eq:dynamic_equlibrium}) \stackrel{(\ref{eq:acceptance_prob_intro})}{\Longrightarrow}
		\forall x,x' \in \Omega :\quad f(x)T(x'|x)a(x'|x) = f(x')T(x|x')a(x|x')
		\label{eq:detailedbalance}
	\end{equation}
	Dies lässt noch immer verschiedene Möglichkeiten zu, die Akzeptanzwahrscheinlichkeit zu bestimmen. Eine effiziente und dadurch beliebte Wahl ist dabei Folgende: ist $f(x')>f(x)$, nehmen wir den neuen Zustand auf jeden Fall an, ansonsten mit der Wahrscheinlichkeit $(f(x')T(x|x'))/(f(x)T(x'|x))$. Dies lässt sich als
	\begin{equation}
		a(x'|x)=\text{min}\left(1,\frac{f(x')T(x|x')}{f(x)T(x'|x)}\right)
		\label{eq:acceptanceratio}
	\end{equation}
	zusammenfassen.
	Diese Wahl der Akzeptanzwahrscheinlichkeit erfüllt die Detailed--Balance--Bedingung (\ref{eq:detailedbalance}).
	
	
	
	\paragraph{Pseudocode:}
	In Pseudocode sieht der Algorithmus dann wie folgt aus:
	\begin{algorithmic}
		\STATE $x_1 \leftarrow$ Anfangszustand
		\FOR{$i=1$ to $N$}
			\STATE $x'\leftarrow$ ziehe Wert gemäß $T(x'|x_i)$
			\STATE $a(x'|x_i) \leftarrow \text{min}\left(1, \frac{f(x')T(x|x')}{f(x)T(x'|x)}\right)$
			\STATE $u\leftarrow$ Zufallszahl aus $[0,1]$
			\IF{$u < a(x'|x_i)$}	\STATE $x_{i+1} \leftarrow x'$
			\ELSE	\STATE $x_{i+1} \leftarrow x_i$
			\ENDIF
	  \ENDFOR
	\end{algorithmic}
	Als Ergebnis erhalten wir eine Liste von Werten, die gemäß $f$ verteilt sind.
	Die Tatsache, dass die Normierung von $f$ für die Funktion des Verfahrens nicht notwendig ist, kann einerseits von Vorteil sein, und bei bestimmten Problemen die effiziente Generierung einer Stichprobe erst möglich machen. Sie bedeutet allerdings, dass wir uns bei Bedarf eine Normierung auf andere Weise beschaffen müssen, da die gezogenen Werte ebenfalls nicht normiert sind. Die Werte sind außerdem nicht unabhängig, sondern im Gegenteil häufig stark korreliert.

	\paragraph{Konvergenz:}Bei klassischer Monte--Carlo--Integration hatten wir in Abschnitt \ref{subsec:integrationsproblem_comparison} gezeigt, dass bei einer Standard--Abweichung eines Wertes von $$\sigma^*:=\sigma\left[\frac{f(X_i)}{p(X_i)}\right]$$ die Standard--Abweichung des Mittelwertes von N unabhängig gezogenen Werten $\sigma^*/\sqrt{N}$ beträgt. Sind die Werte hingegen korreliert, gilt für die Standard--Abweichung des Mittelwertes die Abschätzung \citep[siehe][VII.\;\S3(8)]{Renyi:1964p10655}
	$$\sigma\leq \sigma^*\sqrt{\frac{1+2\sum_{i=1}^N R(i)}{N}},$$
	wobei $R(|j-i|)\leq 1$ eine obere Schranke für die Korrelation zwischen $f(X_i)/p(X_i)$ und $f(X_j)/p(X_j)$ ist.
	Eine große Korrelation kann sich also negativ auf die Konvergenzrate des Mittelwertes (und anderer statistischer Kenngrößen) auswirken. Daher gilt es bei der Konstruktion einer Mutation zwei Aspekte gegeneinander abzuwägen: einerseits ist es wünschenswert, in einem Mutationsschritt möglichst ``große Schritte'' zu machen, um die Korrelation der Werte kleinzuhalten, andererseits ist es in selten gezogenen Bereichen mit hohem Beitrag wünschenswert kleine Schritte zu machen, um diesen Bereich gut abzudecken. Während erstgenannte Vorgehensweise meist mit einer kleinen Akzeptanzwahrscheinlichkeit einhergeht, führen kleine Mutationen tendenziell zu hohen Akzeptanzwahrscheinlichkeiten. Beide ziehen aber in zu extremer Form hohe Korrelation der Samples nach sich, bei zu großen Schritten aufgrund der geringen Akzeptanzwahrscheinlichkeit und daher mehrfacher Gewichtung desselben Samples, bei zu kleinen Schritten aufgrund der großen Ähnlichkeit der vorgeschlagenen Samples. Daher sind sowohl zu hohe als auch zu kleine Akzeptanzwahrscheinlichkeiten meistens ein Zeichen suboptimalen Samplings. \citet{Roberts:1997p5198} empfiehlt zur Steuerung der Mutationsstärke für die Akzeptanzwahrscheinlichkeit einen anzustrebenden Wert von $\approx 0.23$ bei hochdimensionalen Problemen.

	
	
	\section{Robuster Metropolis--Hastings--Algorithmus}\label{sec:robustmetropolis}
	Wir haben in Abschnitt \ref{subsec:importancesampling} festgestellt, dass die Effizienz des einfachen Monte--Carlo--Schätzers erheblich verbessert werden kann, wenn für {\em Importance Sampling} eine geeignete A--priori--Wahrscheinlichkeitsdichte $p$ bekannt ist, aus der wir Werte ziehen können. Parallel dazu haben wir im vorigen Abschnitt gesehen, dass es auch für ein effizientes Funktionieren des {\em Metropolis--Hastings--Algorithmus} wichtig ist, die Mutationen an das Problem anzupassen. Meistens geschieht dies dadurch, dass verschiedene Mutationen erdacht werden, die jeweils in einem Teilbereich des Zustandsraumes effizient sind. Als Beispiel könnten wir bei jedem neuen Sample zufällig zwischen einer Mutation, die große Schritte macht und einer anderen, die nur kleine Veränderungen vornimmt, wählen. Zur Generierung eines neuen Samples wird dann zufällig eine der Mutationen ausgewählt und auf das letzte Sample angewandt.
	
	\citet{Kelemen:2002p8514} schlagen hingegen eine elegante Variante des Metropolis--Algorithmus vor, die im Wesentlichen mit nur einer Mutation auskommt und trotzdem über die gewünschte Eigenschaft verfügt, sich an die lokalen Gegebenheiten anpassen zu können. Dem Verfahren liegt dabei folgende Idee zugrunde: Wenn es möglich wäre, den Zustandsraum $\Omega$ und die Wahrscheinlichkeitsdichte $f$ so zu transformieren, dass $f$ gleichmäßiger verteilt ist, dann würde es ausreichen, eine einzige Mutation auf diesem transformierten Zustandsraum operieren zu lassen. Dann würden Teilgebiete von $\Omega$ mit hohen Spitzenwerten in $f$ zu größeren Gebieten ``gedehnt'', und größere Teilgebiete mit kleinen $f$--Werten ``gestaucht'' werden, und $f$ dadurch gleichmäßiger werden lassen. Eine Mutation, die auf dem transformierten Zustandsraum operiert, würde dann automatisch dort kleinere Schritte machen, wo $f$ plötzlich groß wird und größere Schritte dort, wo $f$ flach und klein ist.
	
	Solch eine Transformation bekommen wir ``geschenkt'', falls wir Punkte im Zustandsraum mittels {\em Importance Sampling} generieren, was bei komplizierteren Problemen (wie dem Strahlungstransportproblem) ohnehin meist der Fall ist (siehe Abschnitt \ref{sec:mc_radiativetransfer}). Schauen wir uns dazu als Beispiel das Integrationsproblem
	\begin{equation}
		I=\int_\Omega f(x) d\mu(x)\approx \frac{1}{N}\sum_{i=0}^{N-1} \frac{f(X_i)}{p(X_i)}
		\label{eq:transformedintegral1}
	\end{equation}
	aus Abschnitt \ref{subsec:integrationsproblem} an. Die Samples aus $p$ werden zumeist durch Transformation gleichförmig verteilter Zufallszahlen aus dem Einheitsinterval $[0,1]$ generiert. Daher können wir eine gezogene Konfiguration von (potentiell unendlich vielen) Zufallszahlen als Koordinaten im unendlichdimensionalen Einheitswürfel $[0,1]^\infty$ auffassen. Nennen wir diesen den {\em primären Sample--Raum} $\mathcal{U}$ und bezeichnen die Transformation vom primären Sample--Raum in unseren Zustandsraum als
	$$S : \mathcal{U} \to \Omega\,,\quad x=S(u).$$
	Dann können wir unser Integral (\ref{eq:transformedintegral1}) auch als transformiertes Integral
	$$I=\int_\mathcal{U} f(S(u)) \left|\frac{dS(u)}{du}\right|du=\int_\mathcal{U} \frac{f(S(u))}{p_S(u)}du$$
	schreiben, wobei
	$$\left|\frac{dS(u)}{du}\right|=\frac{1}{p_S(u)}$$
	die Jacobi--Determinante der Abbildung $S$ ist. Bildlich gesprochen drückt die Jacobi--Determinante die lokale Dehnung bzw. Stauchung einer Transformation zwischen zwei Räumen aus. Wenn $u$ also eine gleichmäßig verteilte Zufallsvariable darstellt, ist $p_S(u)$ die Wahrscheinlichkeitsdichte von $x=S(u)$. Da $S$ die Zufallszahlen aus dem primären Sample--Raum vermehrt auf Punkte im Zustandsraum $\Omega$ mit hohem $f$ abbildet, variiert unser neuer Integrand $f(S(u))/p_S(u)$ nicht mehr so stark, ist also flacher geworden. Unsere Mutation, die nun im primären Sample--Raum mit konstanter durchschnittlicher Schrittweite agiert, passt sich dadurch automatisch an die lokalen Gegebenheiten an, d.h. sie macht kleine Schritte in $\Omega$ wenn $f$ groß ist, und größere Schritte, wenn $f$ klein ist. Die Effizienz des Verfahrens können wir also dadurch verbessern, dass wir das Importance Sampling besser auf das Problem abstimmen. Die Tatsache, dass die Mutationen indirekt durch die Transformation vom primären Sampleraum in den Zustandsraum definiert werden, erhöht die Modularität und damit die Wiederverwendbarkeit des Algorithmus in Form eines Computerprogramms (siehe dazu Abschnitt \ref{cha:program_description} für Details).

	Zum Vorschlagen neuer Samples benutzen wir zwei Mutationen. Zum einen können durch Wählen eines neuen Satzes gleichförmig verteilter Zufallszahlen aus $\mathcal{U}$ {\em frische} Samples vorgeschlagen werden. Dies stellt sicher, dass jeder Punkt in $\mathcal{U}$ bzw. $\Omega$ erreicht werden kann und stellt so die Ergodizität des Verfahrens sicher und macht es robuster. Bei sehr schwierigen Sampling--Problemen verhält sich das Verfahren dann schlimmstenfalls wie ein klassischer Monte--Carlo--Sampler mit Importance Sampling, bei dem jedes Sample unabhängig gezogen wird.
	Die andere Mutation addiert zu den vorhandenen Koordinaten des aktuellen Samples aus $\mathcal{U}$ jeweils eine kleine Störung, so dass jede Koordinate sich ändert aber mit großer Wahrscheinlichkeit in der Nähe der alten Koordinate landet. Die Störung ist dabei symmetrisch um Null, d.h. es ist gleichwahrscheinlich einen Versatz $\Delta u$ zu ziehen wie $-\Delta u$. Die Koordinaten werden dabei als periodisch angesehen, d.h. bei Überschreiten des rechten Randes von $[0,1]$ wird der ganzzahlige Teil abgeschnitten, um wieder im Einheitsintervall zu landen. Dies birgt einen Effizienz--Vorteil, da die Symmetrie der Störung bedeutet, dass für die Übergangswahrscheinlichkeiten
	\begin{equation}
	  T(u'|u)=T(u|u')
	  \label{eq:symmetric_transitionprob}
	\end{equation}
	gilt und sie sich daher in der Berechnung der Akzeptanzwahrscheinlichkeit
	$$a(u'|u)=\text{min}\left(1,\frac{f(S(u'))T(u|u')}{f(S(u))T(u'|u)}\right)\stackrel{(\ref{eq:symmetric_transitionprob})}{=}\text{min}\left(1,\frac{f(S(u'))}{f(S(u))}\right)$$
	herauskürzt. Im Falle der {\em frischen Mutation} kürzt sich die Übergangswahrscheinlichkeit $T$ ebenfalls heraus, da aus $\mathcal{U}$ gleichmäßig gezogen wird.
	In Pseudocode sieht der Algorithmus dann wie folgt aus:
	\begin{algorithmic}
		\STATE $u \leftarrow$ Anfangszustand
		\STATE $x_1 \leftarrow S(u)$
		\FOR{$i=1$ to $N$}
			\STATE $r\leftarrow$ Zufallszahl aus $[0,1]$
			\IF[Mutation schlägt frisches Sample vor]{$r < p_\text{fresh}$}
						\STATE $T \leftarrow T_\text{fresh}$
			\ELSE[Mutation schlägt leicht abgewandeltes Sample vor]	\STATE $T \leftarrow T_\text{perturb}$
			\ENDIF
			\STATE $u'\leftarrow$ ziehe Wert gemäß $T(u'|u)$
			\STATE $x' \leftarrow S(u')$
			\STATE $a(u'|u) \leftarrow \text{min}\left(1,\frac{f(x')}{f(x_i)}\right)$
			\STATE $r\leftarrow$ Zufallszahl aus $[0,1]$
			\IF{$r < a(u'|u)$}
			  \STATE $x_{i+1} \leftarrow x'$
			  \STATE $u \leftarrow u'$
			\ELSE	\STATE $x_{i+1} \leftarrow x_i$
			\ENDIF
	  \ENDFOR
	\end{algorithmic}

