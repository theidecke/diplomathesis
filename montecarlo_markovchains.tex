	\chapter{Monte--Carlo--Markov--Chain--Verfahren}
	Bisher sind wir bei unserem Monte--Carlo--Sch"atzer (\ref{eq:mc_integral}) von einer zugrundeliegenden Stichprobe aus $N$ unabh"angigen und identisch gem"a"s $p$ verteilten St"utzstellen ausgegangen, deren zugeh"rige Funktionswerte gemittelt als Sch"atzer f"ur den Wert des Integrals (\ref{eq:integration_problem}) dienen. Wenn wir aber unsere Funktionswerte in jedem Fall mitteln, dann ist die Unabh"angigkeit der gezogenen St"utzstellen nicht relevant, da die Reihenfolge, in der sie gezogen werden, den Mittelwert nicht beeinflusst. Essentiell ist also lediglich, dass sie identisch gem"a"s $p$ verteilt sind.
	
	Diese Freiheit nutzen sogenannte Monte--Carlo--Markov--Chain--Verfahren (MCMC--Verfahren). Sie stellen ein Verfahren dar, um aus einem Zustandsraum $\Omega$ gem"a"s einer gegebenen Wahrscheinlichkeitsdichte $p$ verteilte Werte zu ziehen. Dies wird durch die Konstruktion eines Zufallspfads ({\em random~walk}) im Zustandsraum, dirigiert durch eine Markov--Kette, erreicht. Dabei mu"s sichergestellt werden, da"s die so erzeugten Werte auch gem"a"s $p$ verteilt sind und insbesondere jeder Punkt im Zustandsraum, auf dem $p$ nicht verschwindet, auch erreicht werden kann.
	
	Wie im n"achsten Abschnitt gezeigt wird, ist dies mit erstaunlich wenig Aufwand m"oglich. Die Kombination aus Vielseitigkeit, M"achtigkeit und Einfachheit hat MCMC--Verfahren in vielen Bereichen\footnote{Beispiele finden sich u.a. in der statistischen Physik, in der Finanzmathematik und zur Berechnung von A--posteriori--Wahrscheinlichkeiten in der Bayes'schen Statistik \citep{Geweke:1989p10465}, z.B. mit Anwendungen in der Bioinformatik und Medizin. Weitere interessante und ungew"ohnliche Anwendungen finden sich in \citep{Diaconis:2009p4122}} zu einem Hauptverfahrensbestandteil gemacht.
	
	
	\section{Metropolis--Hastings--Algorithmus}
	Unter den MCMC--Verfahren ist eines der bekanntesten der {\em Metropolis--Hastings--Algorithmus} (MH), der durch eine Arbeit in der statistischen Physik von \citet{Metropolis:1953p3364} in einer einfachen Form vorgestellt und sp"ater durch \citet{Hastings:1970p3387} verallgemeinert wurde.

	Beim MH--Algorithmus ziehen wir aus einem Zustandsraum $\Omega$ Elemente $x \in \Omega$ gem"a"s der (nicht notwendigerweise normierten!) Wahrscheinlichkeitsdichte $f : \Omega \rightarrow \mathbb{R}_{\geq 0}$. Die Elemente werden dabei mit einem Zufallspfad durch den Zustandsraum generiert. Wir ver"andern dazu den aktuellen Zustand $x$ nach einem frei w"ahlbaren Schema (im Folgenden Mutation genannt) in einen neuen Zustand $x'$.
	Dabei stellen wir folgende Bedingungen an eine Mutation:
	\begin{itemize}
		\item{wenn der "Ubergang von Zustand $x$ nach $x'$ m"oglich ist, muss auch der "Ubergang zur"uck von $x'$ nach $x$ m"oglich sein}
		\item{es muss jeder Zustand $x \in \Omega$ durch eine Kette von "Uberg"angen erreichbar sein (Ergodizit"at)}
		\item{Die "Ubergangswahrscheinlichkeit $T(x'|x)$ durch unser Mutations--Schema von Zustand $x$ zum Zustand $x'$ zu kommen muss f"ur gegebenes $x$ und $x'$ berechenbar sein}
	\end{itemize}
	Mutationen sind also, etwas formaler formuliert, bedingte Wahrscheinlichkeitsverteilungen, die durch das Herkunftselement parametrisiert sind, nicht normiert sein m"ussen und f"ur die
	$$\forall x,x'\in\Omega : \quad T(x'|x)>0 \Leftrightarrow T(x|x')>0$$
	wahr ist. Hierin k"onnen wir eine Parallele zum {\em Importance Sampling} aus Abschnitt \ref{subsec:importancesampling} entdecken, bei dem wir auch die A--priori--Wahr\-schein\-lich\-keits\-ver\-tei\-lung, aus der die Werte gezogen werden, selber w"ahlen k"onnen ohne das Ergebnis der Integration zu verf"alschen. W"ahrend wir uns beim Importance Sampling allerdings f"ur eine einzige Verteilung zur Generierung der gesamten Stichprobe entscheiden m"ussen, haben wir beim {\em MH--Algorithmus} die M"oglichkeit, f"ur jeden aktuellen Zustand eine eigene Verteilung festzulegen aus der ein Vorschlag f"ur den neuen Zustand gezogen wird.
	Das bedeutet, Mutationen k"onnen (und sollten) f"ur effizientes und verl"assliches Verhalten an das spezifische Samplingproblem angepasst werden indem die Eigenschaften der interessierenden Wahrscheinlichkeitsdichte $f$ und des Zustandsraumes $\Omega$ miteinbezogen werden. Sind beispielsweise exakte oder n"aherungsweise g"ultige Invarianten von $f$ bez"uglich seiner Zustandsraumkoordinaten bekannt, k"onnen diese genutzt werden, um Samples "ahnlicher Wahrscheinlichkeitsdichte aber gering korrelierten Zustandsraumkoordinaten zu ziehen.
	
		
	\paragraph{Detailed Balance:}
	Da die Mutation, mit der wir den neuen Zustand generieren, nichts mit der Wahrscheinlichkeitsdichte $f$ zu tun haben mu"s, brauchen wir eine M"oglichkeit die Verteilung der Zust"ande gem"a"s $f$ trotzdem sicherzustellen.
	
	Betrachten wir eine gro"se Zahl von gleichartigen aber unabh"angigen Markov--Ketten, die alle mit einer gewissen Wahrscheinlichkeit $p(x'|x)$ vom Zustand $x$ in den Zustand $x'$ "ubergehen, dann ist eine M"oglichkeit eine station"are Zustandsdichte $f$, gemittelt "uber die aktuellen Zust"ande aller Markov--Ketten, zu erreichen, zu verlangen, da"s
	\begin{equation}
		\forall x,x' \in \Omega :\quad f(x)p(x'|x) = f(x')p(x|x')
		\label{eq:dynamic_equlibrium}
	\end{equation}
	({\em =Detailed Balance}) gilt, d.h. da"s die "Ubergangsraten zwischen zwei beliebigen Zust"anden sich im dynamischen Gleichgewicht befinden.
	Da $T$ die "Ubergangswahrscheinlichkeiten aber schon festlegt, behalten wir uns das Recht vor, einen durch Ziehen aus $T$ vorgeschlagenen Zustands"ubergang nur mit der Wahrscheinlichkeit $a(x'|x)$ anzunehmen und ansonsten abzulehnen,	um {\em Detailed Balance} sicherstellen zu k"onnen:
	\begin{equation}
		p(x'|x) = T(x'|x)a(x'|x)
		\label{eq:acceptance_prob_intro}
	\end{equation}
	\begin{equation}
		(\ref{eq:dynamic_equlibrium}) \stackrel{(\ref{eq:acceptance_prob_intro})}{\Longrightarrow}
		\forall x,x' \in \Omega :\quad f(x)T(x'|x)a(x'|x) = f(x')T(x|x')a(x|x')
		\label{eq:detailedbalance}
	\end{equation}
	Dies l"asst noch immer verschiedene M"oglichkeiten zu, die Akzeptanzwahrscheinlichkeit zu bestimmen. Eine effiziente und dadurch beliebte Wahl ist dabei Folgende: ist $f(x')>f(x)$ nehmen wir den neuen Zustand auf jeden Fall an, ansonsten mit der Wahrscheinlichkeit $(f(x')T(x|x'))/(f(x)T(x'|x))$. Dies l"asst sich zusammenfassen zu
	\begin{equation}
		a(x'|x)=\text{min}\left(1,\frac{f(x')T(x|x')}{f(x)T(x'|x)}\right)
		\label{eq:acceptanceratio}
	\end{equation}
	Diese Wahl der Akzeptanzwahrscheinlichkeit erf"ullt die Detailed--Balance--Bedingung (\ref{eq:detailedbalance}).
	
	
	
	\paragraph{Pseudocode:}
	In Pseudocode sieht der Algorithmus dann wie folgt aus:
	\begin{algorithmic}
		\STATE $x_1 \leftarrow$ Anfangszustand
		\FOR{$i=1$ to $N$}
			\STATE $x'\leftarrow$ ziehe Wert gem"a"s $T(x'|x_i)$
			\STATE $a(x'|x_i) \leftarrow \text{min}\left(1, \frac{f(x')T(x|x')}{f(x)T(x'|x)}\right)$
			\STATE $u\leftarrow$ Zufallszahl aus $[0,1]$
			\IF{$u < a(x'|x_i)$}	\STATE $x_{i+1} \leftarrow x'$
			\ELSE	\STATE $x_{i+1} \leftarrow x_i$
			\ENDIF
	  \ENDFOR
	\end{algorithmic}
	Als Ergebnis erhalten wir eine Liste von Werten, die gem"a"s $f$ verteilt sind.
	Die Tatsache, da"s die Normierung von $f$ f"ur die Funktion des Verfahrens nicht notwendig ist, kann einerseits von Vorteil sein, und bei bestimmten Problemen die effiziente Generierung einer Stichprobe erst m"oglich machen, sie bedeutet allerdings, da"s wir uns bei Bedarf eine Normierung auf andere Weise beschaffen m"ussen, da die gezogenen Werte ebenfalls nicht normiert sind. Die Werte sind ausserdem nicht unabh"angig, sondern im Gegenteil h"aufig stark korreliert.

	\paragraph{Konvergenz:}Bei klassischer Monte--Carlo--Integration hatten wir in Abschnitt \ref{subsec:integrationsproblem_comparison} gezeigt, da"s bei einer Standard--Abweichung eines Wertes von $$\sigma^*:=\sigma\left[\frac{f(X_i)}{p(X_i)}\right]$$ die Standard--Abweichung des Mittelwertes von N unabh"angig gezogenen Werten $\sigma^*/\sqrt{N}$ betr"agt. Sind die Werte hingegen korreliert, gilt f"ur die Standard--Abweichung des Mittelwertes die Absch"atzung \citep[siehe][VII.\;\S3(8)]{Renyi:1964p10655}
	$$\sigma\leq \sigma^*\sqrt{\frac{1+2\sum_{i=1}^N R(i)}{N}},$$
	wobei $R(|j-i|)\leq 1$ eine obere Schranke f"ur die Korrelation zwischen $f(X_i)/p(X_i)$ und $f(X_j)/p(X_j)$ ist.
	Eine gro"se Korrelation kann sich also negativ auf die Konvergenzrate des Mittelwertes (und anderer statistischer Kenngr"o"sen) auswirken. Daher gilt es bei der Konstruktion einer Mutation zwei Aspekte gegeneinander abzuw"agen: einerseits ist es w"unschenswert in einem Mutationsschritt m"oglichst ``gro"se Schritte'' zu machen um die Korrelation der Werte kleinzuhalten, andererseits ist es in selten gezogenen Bereichen mit hohem Beitrag w"unschenswert kleine Schritte zu machen, um diesen Bereich gut abzudecken. W"ahrend ersteres Verfahren meist mit einer kleinen Akzeptanzwahrscheinlichkeit einhergeht, f"uhren kleine Mutationen tendenziell zu hohen Akzeptanzwahrscheinlichkeiten. Beide ziehen aber in zu extremer Form hohe Korrelation der Samples nach sich, bei zu gro"sen Schritten aufgrund der geringen Akzeptanzwahrscheinlichkeit und daher mehrfacher Gewichtung desselben Samples, bei zu kleinen Schritten aufgrund der gro"sen "Ahnlichkeit der vorgeschlagenen Samples. Daher sind sowohl zu hohe als auch zu kleine Akzeptanzwahrscheinlichkeiten meistens ein Zeichen suboptimalen Samplings. In \citep{Roberts:1997p5198} wird zur Steuerung der Mutationsst"arke f"ur die Akzeptanzwahrscheinlichkeit ein anzustrebender Wert von $\approx 0.23$ bei hochdimensionalen Problemen empfohlen.

	
	
	\section{Robuster Metropolis--Hastings--Algorithmus}
	Wir haben in Abschnitt \ref{subsec:importancesampling} festgestellt, da"s die Effizienz des einfachen Monte--Carlo--Sch"atzers erheblich verbessert werden kann, wenn f"ur {\em Importance Sampling} eine geeignete A--priori--Wahrscheinlichkeitsdichte $p$ bekannt und samplebar ist. Parallel dazu haben wir im vorigen Abschnitt gesehen, da"s es auch f"ur ein effizientes Funktionieren des {\em Metropolis--Hastings--Algorithmus} wichtig ist, die Mutationen an das Problem anzupassen. Meistens geschieht dies dadurch, da"s verschiedene Mutationen erdacht werden, die jeweils in einem Teilbereich des Zustandsraumes effizient sind. Beispielsweise eine Mutation die gro"se Schritte macht und eine andere die nur kleine Ver"anderungen vornimmt. Zur Generierung eines neuen Samples wird dann zuf"allig eine der Mutationen ausgew"ahlt und auf das letzte Sample angewandt.
	
	In \citep{Kelemen:2002p8514} wird hingegen eine elegante Variante des Metropolis--Algorithmus vorgeschlagen die im Wesentlichen mit nur einer Mutation auskommt und trotzdem "uber die gew"unschte Eigenschaft verf"ugt sich an die lokalen Gegebenheiten anpassen zu k"onnen. Dem Verfahren liegt dabei folgende Idee zugrunde: Wenn es m"oglich w"are den Zustandsraum $\Omega$ und die Wahrscheinlichkeitsdichte $f$ so zu transformieren, 	da"s $f$ gleichm"assiger verteilt ist, dann w"urde es ausreichen eine einzige Mutation auf diesem transformierten Zustandsraum operieren zu lassen. Dann w"urden Teilgebiete von $\Omega$ mit hohen Peaks in $f$ zu gr"o"seren Gebieten ``gedehnt'', und gr"o"sere Teilgebiete mit kleinen $f$--Werten ``gestaucht'' werden, und $f$ dadurch gleichm"assiger werden lassen. Eine Mutation, die auf dem transformierten Zustandsraum operiert w"urde dann automatisch dort kleinere Schritte machen, wo $f$ pl"otzlich gro"s wird und gr"o"sere Schritte dort, wo $f$ flach und klein ist.
	
	Solch eine Transformation bekommen wir geschenkt, falls wir Punkte im Zustandsraum mittels {\em Importance Sampling} generieren, was bei komplizierteren Problemen (wie dem Strahlungstransportproblem) sowieso meist der Fall ist (siehe Abschnitt \ref{sec:mc_radiativetransfer}). Schauen wir uns dazu als Beispiel das Integrationsproblem
	\begin{equation}
		I=\int_\Omega f(x) d\mu(x)\approx \frac{1}{N}\sum_{i=0}^{N-1} \frac{f(X_i)}{p(X_i)}
		\label{eq:transformedintegral1}
	\end{equation}
	aus Abschnitt \ref{subsec:integrationsproblem} an. Die Samples aus $p$ werden zumeist durch Transformation gleichf"ormig verteilter Zufallszahlen aus dem Einheitsinterval $[0,1]$ generiert. Daher k"onnen wir eine gezogene Konfiguration von (potentiell unendlich vielen) Zufallszahlen als Koordinaten im unendlichdimensionalen Einheitsw"urfel $[0,1]^\infty$ auffassen. Nennen wir diesen den {\em prim"aren Sample--Raum} $\mathcal{U}$ und bezeichnen die Transformation vom prim"aren Sample--Raum in unseren Zustandsraum als
	$$S : \mathcal{U} \to \Omega\,,\quad x=S(u).$$
	Dann k"onnen wir unser Integral (\ref{eq:transformedintegral1}) auch als transformiertes Integral
	$$I=\int_\mathcal{U} f(S(u)) \left|\frac{dS(u)}{du}\right|du=\int_\mathcal{U} \frac{f(S(u))}{p_S(u)}du$$
	schreiben, wobei
	$$\left|\frac{dS(u)}{du}\right|=\frac{1}{p_S(u)}$$
	die Jacobi--Determinante der Abbildung $S$ ist. Bildlich gesproche dr"uckt die Jacobi--Determinante die lokale Dehnung bzw. Stauchung einer Transformation zwischen zwei R"aumen aus. Wenn $u$ also eine gleichm"assig verteilte Zufallsvariable darstellt, ist $p_S(u)$ die Wahrscheinlichkeitsdichte von $x=S(u)$. Da $S$ die Zufallszahlen aus dem prim"aren Sample--Raum vermehrt auf Punkte im Zustandsraum $\Omega$ mit hohem $f$ abbildet variiert unser neuer Integrand $f(S(u))/p_S(u)$ nicht mehr so stark, ist also flacher geworden. Unsere Mutation die nun im prim"aren Sample--Raum mit konstanter durchschnittlicher Schrittweite agiert, passt sich dadurch automatisch an die lokalen Gegebenheiten an, d.h. sie macht kleine Schritte in $\Omega$ wenn $f$ gro"s ist und gr"o"sere Schritte wenn $f$ klein ist. Die Effizienz des Verfahrens k"onnen wir nun also dadurch verbessern, da"s wir das Importance Sampling besser auf das Problem abstimmen. Der Metropolis--Algorithmus mu"s davon nichts wissen, was auch die Modularit"at des Computerprogramms und somit seine Wiederverwendbarkeit erh"oht.

	Zum Vorschlagen neuer Samples benutzen wir zwei Mutationen. Zum einen k"onnen {\em frische} Samples vorgeschlagen werden, was durch w"ahlen eines neuen Satzes aus gleichf"ormig verteilten Zufallszahlen aus $\mathcal{U}$ entspricht. Dies stellt sicher, da"s jeder Punkt in $\mathcal{U}$ bzw. $\Omega$ erreicht werden kann und stellt so die Ergodizit"at des Verfahrens sicher und macht es robuster. Bei sehr schwierigen Sampling--Problemen verh"alt sich das Verfahren dann schlimmstenfalls wie ein klassischer Monte--Carlo--Sampler mit Importance Sampling, bei dem jedes Sample unabh"angig gezogen wird.
	Die andere Mutation addiert zu den vorhandenen Koordinaten des aktuellen Samples aus $\mathcal{U}$ jeweils eine kleine St"orung, soda"s jede Koordinate sich "andert aber mit gro"ser Wahrscheinlichkeit in der N"ahe der alten Koordinate landet. Die St"orung ist dabei symmetrisch um Null, d.h. es ist gleichwahrscheinlich einen Versatz $\Delta u$ zu ziehen, wie $-\Delta u$. Die Koordinaten werden dabei als periodisch angesehen, d.h. bei "Uberschreiten des rechten Randes von $[0,1]$ wird der ganzzahlige Teil abgeschnitten um wieder im Einheitsintervall zu landen. Dies birgt einen Effizienz--Vorteil, da die Symmetrie der St"orung bedeutet, da"s f"ur die "Ubergangswahrscheinlichkeiten
	\begin{equation}
	  T(u'|u)=T(u|u')
	  \label{eq:symmetric_transitionprob}
	\end{equation}
	gilt und sie sich daher in der Berechnung der Akzeptanzwahrscheinlichkeit
	$$a(u'|u)=\text{min}\left(1,\frac{f(S(u'))T(u|u')}{f(S(u))T(u'|u)}\right)\stackrel{(\ref{eq:symmetric_transitionprob})}{=}\text{min}\left(1,\frac{f(S(u'))}{f(S(u))}\right)$$
	herausk"urzt. Im Falle der {\em frischen Mutation} k"urzt sich die "Ubergangswahrscheinlichkeit $T$ ebenfalls heraus, da $\mathcal{U}$ gleichm"a"sig gesampled wird.
	In Pseudocode sieht der Algorithmus dann wie folgt aus:
	\begin{algorithmic}
		\STATE $u \leftarrow$ Anfangszustand
		\STATE $x_1 \leftarrow S(u)$
		\FOR{$i=1$ to $N$}
			\STATE $r\leftarrow$ Zufallszahl aus $[0,1]$
			\COMMENT{w"ahle Mutation}
			\IF{$r < p_\text{fresh}$}
						\STATE $T \leftarrow T_\text{fresh}$
			\ELSE	\STATE $T \leftarrow T_\text{perturb}$
			\ENDIF
			\STATE $u'\leftarrow$ ziehe Wert gem"a"s $T(u'|u)$
			\STATE $x' \leftarrow S(u')$
			\STATE $a(u'|u) \leftarrow \text{min}\left(1,\frac{f(x')}{f(x_i)}\right)$
			\STATE $r\leftarrow$ Zufallszahl aus $[0,1]$
			\IF{$r < a(u'|u)$}
			  \STATE $x_{i+1} \leftarrow x'$
			  \STATE $u \leftarrow u'$
			\ELSE	\STATE $x_{i+1} \leftarrow x_i$
			\ENDIF
	  \ENDFOR
	\end{algorithmic}

